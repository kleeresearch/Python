{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleeresearch/Python/blob/master/cvps22_19_mlp_weight_regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1zOSNZOAUQ_"
      },
      "source": [
        "# **CVPS22 // Addressing Overfitting in MLPs**\n",
        "\n",
        "*November 1, 2022*\n",
        "\n",
        "This notebook will explore weight regularization as a method for controlling overfitting.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnoAdkXkfes"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio as iio\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2DDFH1ylC6t"
      },
      "source": [
        "plt.style.use(\"seaborn-dark\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
        "plt.rcParams[\"image.interpolation\"] = \"nearest\"\n",
        "plt.rcParams[\"image.cmap\"] = \"gist_gray\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JQVmSUvveiE"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIZAuCuy76cI"
      },
      "source": [
        "Load the hand-written digits data,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8FMBjNQveZM"
      },
      "source": [
        "# -- load in the hand-written digits data set\n",
        "fname = \"/content/drive/MyDrive/cvps22/data/examples/digits.png\"\n",
        "digits = np.asarray(iio.imread(fname)) / 255.\n",
        "\n",
        "# -- get a list of individual numbers (note they are 20x20 pixels)\n",
        "nums = digits.reshape(50, 20, 100, 20).transpose(0, 2, 1, 3).reshape(5000, 20, 20)\n",
        "\n",
        "# -- create features array [NOTE THE .copy()]\n",
        "nimg = nums.shape[0]\n",
        "nrow = nums.shape[1]\n",
        "ncol = nums.shape[2]\n",
        "feat = nums.reshape(nimg, nrow * ncol).copy()\n",
        "\n",
        "# -- set the target\n",
        "targ = np.concatenate((np.full(500, 0), np.full(500, 1), np.full(500, 2), \n",
        "                       np.full(500, 3), np.full(500, 4), np.full(500, 5), \n",
        "                       np.full(500, 6), np.full(500, 7), np.full(500, 8), \n",
        "                       np.full(500, 9)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKM2PNPVL8JM"
      },
      "source": [
        "# -- create a training/testing sample\n",
        "feat_tr, feat_te, targ_tr, targ_te = train_test_split(feat, targ, test_size=0.2, random_state=302)\n",
        "\n",
        "print(\"number of training examples : {0}\".format(targ_tr.size))\n",
        "print(\"number of testing examples  : {0}\".format(targ_te.size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql_NdA5E75F2"
      },
      "source": [
        "Let's train a **Multi-layer Perceptron classifier**,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaNOVaNEGzO7"
      },
      "source": [
        "# -- instantiate an MLP classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10), max_iter=500)\n",
        "\n",
        "# -- train it\n",
        "mlp.fit(feat_tr, targ_tr)\n",
        "\n",
        "# -- predict\n",
        "pred_tr = mlp.predict(feat_tr)\n",
        "pred_te = mlp.predict(feat_te)\n",
        "\n",
        "# -- print accuracy\n",
        "acc_tr = accuracy_score(targ_tr, pred_tr)\n",
        "acc_te = accuracy_score(targ_te, pred_te)\n",
        "\n",
        "print(\"training accuracy : {0}\".format(acc_tr))\n",
        "print(\"testing accuracy : {0}\".format(acc_te))\n",
        "\n",
        "# -- evaluate performance metrics\n",
        "ConfusionMatrixDisplay.from_estimator(mlp, feat_te, targ_te)\n",
        "print(classification_report(targ_te, pred_te))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnD6QSBhC1bq"
      },
      "source": [
        "# -- plot the loss function\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(mlp.loss_curve_)\n",
        "ax.set_xlabel(\"iteration\")\n",
        "ax.set_ylabel(\"loss\")\n",
        "ax.set_yscale(\"log\")\n",
        "fig.show()\n",
        "\n",
        "# -- visualize the weights\n",
        "ww = mlp.coefs_[0].reshape(20, 20, 10)\n",
        "\n",
        "fig, ax = plt.subplots(2, 5, figsize=[15, 5])\n",
        "for ii in range(10):\n",
        "  ax[ii // 5, ii % 5].imshow(np.abs(ww[:, :, ii]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRut1wWfsd5S"
      },
      "source": [
        "# -- instantiate an MLP classifier with more neurons\n",
        "mlp = \n",
        "\n",
        "# -- train it\n",
        "mlp.fit(feat_tr, targ_tr)\n",
        "\n",
        "# -- predict\n",
        "pred_tr = mlp.predict(feat_tr)\n",
        "pred_te = mlp.predict(feat_te)\n",
        "\n",
        "# -- print accuracy\n",
        "acc_tr = accuracy_score(targ_tr, pred_tr)\n",
        "acc_te = accuracy_score(targ_te, pred_te)\n",
        "\n",
        "print(\"training accuracy : {0}\".format(acc_tr))\n",
        "print(\"testing accuracy : {0}\".format(acc_te))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJJIa541DJ28"
      },
      "source": [
        "# -- visualize the weights\n",
        "ww = \n",
        "\n",
        "fig, ax = plt.subplots(10, 10, figsize=[15, 10])\n",
        "for ii in range(100):\n",
        "  ax[ii // 10, ii % 10].imshow(ww[:, :, ii], cmap=\"coolwarm\", clim=[-0.5, 0.5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3R8QyXon_Ha"
      },
      "source": [
        "This model is clearly overfit.  Let's use weight regularization to reduce the model flexibility,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rWgepg5oAeY"
      },
      "source": [
        "# -- instantiate an MLP classifier with more neurons\n",
        "mlp = \n",
        "\n",
        "# -- train it\n",
        "mlp.fit(feat_tr, targ_tr)\n",
        "\n",
        "# -- predict\n",
        "pred_tr = mlp.predict(feat_tr)\n",
        "pred_te = mlp.predict(feat_te)\n",
        "\n",
        "# -- print accuracy\n",
        "acc_tr = accuracy_score(targ_tr, pred_tr)\n",
        "acc_te = accuracy_score(targ_te, pred_te)\n",
        "\n",
        "print(\"training accuracy : {0}\".format(acc_tr))\n",
        "print(\"testing accuracy : {0}\".format(acc_te))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSN3g9Bho6Xn"
      },
      "source": [
        "# -- visualize the weights\n",
        "ww = \n",
        "\n",
        "fig, ax = plt.subplots(10, 10, figsize=[15, 10])\n",
        "for ii in range(100):\n",
        "  ax[ii // 10, ii % 10].imshow(ww[:, :, ii], cmap=\"coolwarm\", clim=[-0.15, 0.15])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7H-fHNLswdG"
      },
      "source": [
        "# -- plot the loss function\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(mlp.loss_curve_)\n",
        "ax.set_xlabel(\"iteration\")\n",
        "ax.set_ylabel(\"loss\")\n",
        "ax.set_yscale(\"log\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}